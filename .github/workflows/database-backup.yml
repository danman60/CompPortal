name: Database Backup

on:
  schedule:
    # Run daily at 3 AM UTC (11 PM EST / 8 PM PST)
    - cron: '0 3 * * *'
  workflow_dispatch: # Allow manual trigger
  push:
    branches:
      - main
    # TESTING: Runs on every push to main until we confirm backups work

jobs:
  backup:
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          ref: main

      - name: Install PostgreSQL 17 client
        run: |
          # Add PostgreSQL APT repository for version 17
          sudo apt-get update
          sudo apt-get install -y wget ca-certificates
          wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -
          echo "deb http://apt.postgresql.org/pub/repos/apt/ $(lsb_release -cs)-pgdg main" | sudo tee /etc/apt/sources.list.d/pgdg.list
          sudo apt-get update
          sudo apt-get install -y postgresql-client-17

      - name: Verify PostgreSQL version
        run: |
          echo "Checking installed pg_dump version:"
          pg_dump --version
          echo "Expected: PostgreSQL 17.x"

      - name: Generate backup filename
        id: filename
        run: |
          TIMESTAMP=$(date +%Y%m%d_%H%M%S)
          FILENAME="backup_${TIMESTAMP}.sql"
          echo "filename=$FILENAME" >> $GITHUB_OUTPUT
          echo "timestamp=$TIMESTAMP" >> $GITHUB_OUTPUT

      - name: Create database backup
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: |
          # Verify DATABASE_URL is set (without exposing password)
          if [ -z "$DATABASE_URL" ]; then
            echo "ERROR: DATABASE_URL secret is not set or is empty"
            echo "Go to: https://github.com/${{ github.repository }}/settings/secrets/actions"
            echo "Add secret named: DATABASE_URL"
            exit 1
          fi

          echo "✅ DATABASE_URL is set (length: ${#DATABASE_URL} chars)"

          # Create backup directory
          mkdir -p backups

          # Strip query parameters (?pgbouncer=true&connection_limit=1) that pg_dump doesn't understand
          # Vercel adds these for application connections, but pg_dump needs clean URL
          CLEAN_URL="${DATABASE_URL%%\?*}"

          echo "Using transaction pooler (stripped query params for pg_dump compatibility)"

          # Run pg_dump
          pg_dump "$CLEAN_URL" \
            --clean \
            --if-exists \
            --no-owner \
            --no-privileges \
            --format=plain \
            --file=backups/${{ steps.filename.outputs.filename }}

          # Create compressed version
          gzip -k backups/${{ steps.filename.outputs.filename }}

          # Generate backup metadata
          cat > backups/${{ steps.filename.outputs.filename }}.meta << EOF
          Backup Date: $(date -u +"%Y-%m-%d %H:%M:%S UTC")
          Database: CompPortal Production
          Size (uncompressed): $(du -h backups/${{ steps.filename.outputs.filename }} | cut -f1)
          Size (compressed): $(du -h backups/${{ steps.filename.outputs.filename }}.gz | cut -f1)
          GitHub Run: ${{ github.run_id }}
          EOF

      - name: Verify backup integrity
        run: |
          # Check backup file exists and is not empty
          if [ ! -s "backups/${{ steps.filename.outputs.filename }}" ]; then
            echo "ERROR: Backup file is empty or doesn't exist"
            exit 1
          fi

          # Check backup contains expected tables
          if ! grep -q "CREATE TABLE" "backups/${{ steps.filename.outputs.filename }}"; then
            echo "ERROR: Backup doesn't contain CREATE TABLE statements"
            exit 1
          fi

          # Count tables in backup
          TABLE_COUNT=$(grep -c "CREATE TABLE" backups/${{ steps.filename.outputs.filename }} || true)
          echo "✅ Backup contains $TABLE_COUNT tables"

          # Minimum expected tables (adjust based on your schema)
          if [ "$TABLE_COUNT" -lt 20 ]; then
            echo "WARNING: Expected at least 20 tables, found $TABLE_COUNT"
          fi

      - name: Cleanup old backups (keep last 30 days)
        run: |
          # Keep only the 30 most recent backups
          cd backups
          ls -t backup_*.sql.gz | tail -n +31 | xargs -r rm
          ls -t backup_*.sql | tail -n +31 | xargs -r rm
          ls -t backup_*.sql.meta | tail -n +31 | xargs -r rm

          # List remaining backups
          echo "=== Remaining backups ==="
          ls -lh backup_*.sql.gz | tail -n 5

      - name: Commit backup to repository
        run: |
          git config user.name "GitHub Actions Bot"
          git config user.email "actions@github.com"

          git add backups/

          # Only commit if there are changes
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            BACKUP_SIZE=$(du -h backups/${{ steps.filename.outputs.filename }}.gz | cut -f1)
            git commit -m "chore: database backup ${{ steps.filename.outputs.timestamp }}" \
                       -m "Automated daily backup via GitHub Actions" \
                       -m "Backup size: ${BACKUP_SIZE}" \
                       -m "Run ID: ${{ github.run_id }}"
            git push
          fi

      - name: Create GitHub Release with backup (weekly)
        if: github.event.schedule == '0 3 * * 0' # Sunday only
        uses: softprops/action-gh-release@v1
        with:
          tag_name: backup-${{ steps.filename.outputs.timestamp }}
          name: Weekly Backup ${{ steps.filename.outputs.timestamp }}
          body: |
            Automated weekly database backup

            **Backup Details:**
            - Date: ${{ steps.filename.outputs.timestamp }}
            - Format: PostgreSQL SQL dump (gzip compressed)

            **Restoration:**
            ```bash
            # Download and restore
            gunzip backup_${{ steps.filename.outputs.timestamp }}.sql.gz
            psql "$DATABASE_URL" < backup_${{ steps.filename.outputs.timestamp }}.sql
            ```
          files: |
            backups/${{ steps.filename.outputs.filename }}.gz
            backups/${{ steps.filename.outputs.filename }}.meta
          draft: false
          prerelease: false
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Send failure notification (if backup fails)
        if: failure()
        run: |
          echo "❌ DATABASE BACKUP FAILED"
          echo "Run ID: ${{ github.run_id }}"
          echo "Check: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"

          # TODO: Add email/Slack notification here
          # For now, GitHub will send email on workflow failure if configured
